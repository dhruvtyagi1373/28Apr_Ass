{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cecedb79-fd90-4461-8196-cb7226ed9199",
   "metadata": {},
   "source": [
    "## Q1. What is hierarchical clustering, and how is it different from other clustering techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3873af9-b07f-422c-96c0-88aac4e7b947",
   "metadata": {},
   "source": [
    "Sol : Hierarchical clustering is an unsupervised learning technique used to group similar objects into clusters. It creates a hierarchy of clusters by merging or splitting them based on similarity measures.\n",
    "Hierarchical clustering groups similar objects into a dendrogram. It merges similar clusters iteratively, starting with each data point as a separate cluster. This creates a tree-like structure that shows the relationships between clusters and their hierarchy.\n",
    "The advantage of not having to pre-define the number of clusters gives it quite an edge over k-Means."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dfec03-8868-468e-9d95-32025166224f",
   "metadata": {},
   "source": [
    "## Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c57665-030d-4336-9335-a00fa0bdeca2",
   "metadata": {},
   "source": [
    "1. Agglomerative hierarchical clustering : We assign each point to an individual cluster in this technique. Suppose there are 4 data points. We will assign each of these points to a cluster and hence will have 4 clusters in the beginning.Then, at each iteration, we merge the closest pair of clusters and repeat this step until only a single cluster is left.We are merging (or adding) the clusters at each step.Hence, this type of clustering is also known as additive hierarchical clustering.\n",
    "2. Divisive Hierarchical clustering : Divisive hierarchical clustering works in the opposite way. Instead of starting with n clusters (in case of n observations), we start with a single cluster and assign all the points to that cluster.So, it doesnâ€™t matter if we have 10 or 1000 data points. All these points will belong to the same cluster at the beginning.Now, at each iteration, we split the farthest point in the cluster and repeat this process until each cluster only contains a single point.We are splitting (or dividing) the clusters at each step, hence the name divisive hierarchical clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b94f75-a78a-410e-8b8d-8571c551cec0",
   "metadata": {},
   "source": [
    "## Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the common distance metrics used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a52cee-024c-4cd8-be19-ca0ec28cd3f4",
   "metadata": {},
   "source": [
    "Sol : Take the distance between the centroids of the clusters. The points having the least distance are referred to as similar points and we can merge them. We can refer to this as a distance-based algorithm as well (since we are calculating the distances between the clusters).\n",
    "In hierarchical clustering, we have a concept called a proximity matrix. This stores the distances between each point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553cd96-c3e5-4097-bca9-fe3174a70071",
   "metadata": {},
   "source": [
    "## Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some common methods used for this purpose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215df040-d361-4e68-9c5d-8305094055b2",
   "metadata": {},
   "source": [
    "Sol : To get the number of clusters for hierarchical clustering, we make use of an awesome concept called a Dendrogram.\n",
    "A dendrogram is a tree-like diagram that records the sequences of merges or splits.The number of clusters will be the number of vertical lines intersected by the line drawn using the threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d447eab-20e8-46ef-baf7-a34657c98825",
   "metadata": {},
   "source": [
    "## Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd717b42-106d-459f-87b6-f52d25085622",
   "metadata": {},
   "source": [
    "Sol : A dendrogram is a tree-like diagram that records the sequences of merges or splits.We have the samples of the dataset on the x-axis and the distance on the y-axis. Whenever two clusters are merged, we will join them in the dendrogram and the height of the join will be the distance between these points. More the distance of the vertical lines in the dendrogram, more the distance between those clusters.\n",
    "Now, we can set a threshold distance and draw a horizontal line (Generally, we try to set the threshold so that it cuts the tallest vertical line)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07108758-71ca-44cd-b84f-5a3008f0b358",
   "metadata": {},
   "source": [
    "## Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the distance metrics different for each type of data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23710d91-37bd-4f6d-ba5b-9036f780ef5a",
   "metadata": {},
   "source": [
    "Yes,it can be used. \n",
    "These methods are as follows:\n",
    "1. Gower Distance.\n",
    "2. Dimensionality Reduction Techniques.\n",
    "3. Recode Categorical Variables.\n",
    "4. Recode Continuous Variables.\n",
    "5. K-prototypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7427a3a-a30f-4aa8-aec7-0403274e0741",
   "metadata": {},
   "source": [
    "## Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f6a0b-2d08-43bc-9f42-861294f5543a",
   "metadata": {},
   "source": [
    "Sol : In case of hierarchical clustering, by using dendrogram outliers are found. For outlier detection in Hierarchical Clustering, it depends\n",
    "on dendrogram,here we have to find Cophenetic\n",
    "Correlation Coefficient for particular dataset after running\n",
    "the algorithm. The steps are discussed below:\n",
    "- Run Hierarchical clustering algorithm and find out dendrogram and Cophenetic Correlation Coefficient.\n",
    "- From dendrogram we can visualize which cluster is outer from other cluster.\n",
    "- Find those data which belong to this cluster and consider those as outlier.\n",
    "- Remove those data from dataset and again run Hierarchical algorithm.\n",
    "- Find Cophenetic Correlation Coefficient and it will be increased."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
